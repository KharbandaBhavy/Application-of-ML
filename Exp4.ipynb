{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propogation Algorithm in ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code by Bhavy Kharbanda\n",
    "# Sap Id: 500082531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# https://intellipaat.com/blog/tutorial/artificial-intelligence-tutorial/back-propagation-algorithm/\n",
    "# https://www.guru99.com/backpropogation-neural-network.html#2\n",
    "# https://www.youtube.com/watch?v=ayOOMlgb320\n",
    "# https://www.youtube.com/watch?v=GltT9b31fRY&t=656s\n",
    "# https://www.youtube.com/watch?v=0e0z28wAWfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation is the essence of neural network training. It is the method of fine-tuning the weights of a neural network based on the error rate obtained in the previous epoch (i.e., iteration). Proper tuning of the weights allows you to reduce error rates and make the model reliable by increasing its generalization.\n",
    "\n",
    "# Backpropagation in neural network is a short form for “backward propagation of errors.” It is a standard method of training artificial neural networks. This method helps calculate the gradient of a loss function with respect to all the weights in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working of Back Propogation Algorithm\n",
    "# 1. Inputs X, arrive through the preconnected path\n",
    "# 2. Input is modeled using real weights W. The weights are usually randomly selected.\n",
    "# 3. Calculate the output for every neuron from the input layer, to the hidden layers, to the output layer.\n",
    "# 4. Calculate the error in the outputs\n",
    "#   ErrorB= Actual Output – Desired Output\n",
    "# 5. Travel back from the output layer to the hidden layer to adjust the weights such that the error is decreased.\n",
    "#   Keep repeating the process until the desired output is achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "X = X/np.amax(X,axis=0) # maximum of X array longitudinally y = y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid Function \n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Derivative of Sigmoid Function \n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable initialization\n",
    "epoch=5000\t#Setting training iterations \n",
    "lr=0.1\t#Setting learning rate\n",
    "inputlayer_neurons = 2\t#number of features in data set \n",
    "hiddenlayer_neurons = 3\t#number of hidden layers neurons \n",
    "output_neurons = 1\t#number of neurons at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight and bias initialization \n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons)) \n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draws a random range of numbers uniformly of dim x*y \n",
    "for i in range(epoch):\n",
    "\n",
    "#Forward Propogation \n",
    "    hinp1=np.dot(X,wh) \n",
    "    hinp=hinp1 + bh\n",
    "    hlayer_act = sigmoid(hinp) \n",
    "    outinp1=np.dot(hlayer_act,wout) \n",
    "    outinp= outinp1+ bout\n",
    "    output = sigmoid(outinp)\n",
    "\n",
    "\n",
    "    #Backpropagation \n",
    "    EO = y-output\n",
    "    outgrad = derivatives_sigmoid(output) \n",
    "    d_output = EO* outgrad\n",
    "    EH = d_output.dot(wout.T)\n",
    "\n",
    "    #how much hidden layer wts contributed to error h\n",
    "    hiddengrad = derivatives_sigmoid(hlayer_act) \n",
    "    d_hiddenlayer = EH * hiddengrad\n",
    "\n",
    "    # dotproduct of nextlayererror and currentlayerop \n",
    "    wout += hlayer_act.T.dot(d_output) *lr\n",
    "    wh += X.T.dot(d_hiddenlayer) *lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "\n",
      "Actual Output: \n",
      "[[92.]\n",
      " [86.]\n",
      " [89.]]\n",
      "\n",
      "Predicted Output: \n",
      " [[0.99999843]\n",
      " [0.99999436]\n",
      " [0.99999842]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInput: \\n\" + str(X)) \n",
    "print(\"\\nActual Output: \\n\" + str(y)) \n",
    "print(\"\\nPredicted Output: \\n\" ,output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ee691e3c2883c6a130fe7a4fe904a1eaf00aeea2af805a016ed0d0bd8e74479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
